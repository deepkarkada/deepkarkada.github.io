---
---

@string{aps = {American Physical Society,}}


@InProceedings{10.1007/978-3-031-08999-2_12,
author="Thakur, Siddhesh P.
and Pati, Sarthak
and Panchumarthy, Ravi
and Karkada, Deepthi
and Wu, Junwen
and Kurtaev, Dmitry
and Sako, Chiharu
and Shah, Prashant
and Bakas, Spyridon",
editor="Crimi, Alessandro
and Bakas, Spyridon",
title="Optimization of Deep Learning Based Brain Extraction in MRI for Low Resource Environments",
booktitle="Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries",
year="2022",
publisher="Springer International Publishing",
address="Cham",
pages="151--167",
abstract="Brain extraction is an indispensable step in neuro-imaging with a direct impact on downstream analyses. Most such methods have been developed for non-pathologically affected brains, and hence tend to suffer in performance when applied on brains with pathologies, e.g., gliomas, multiple sclerosis, traumatic brain injuries. Deep Learning (DL) methodologies for healthcare have shown promising results, but their clinical translation has been limited, primarily due to these methods suffering from i) high computational cost, and ii) specific hardware requirements, e.g., DL acceleration cards. In this study, we explore the potential of mathematical optimizations, towards making DL methods amenable to application in low resource environments. We focus on both the qualitative and quantitative evaluation of such optimizations on an existing DL brain extraction method, designed for pathologically-affected brains and agnostic to the input modality. We conduct direct optimizations and quantization of the trained model (i.e., prior to inference on new data). Our results yield substantial gains, in terms of speedup, latency, throughput, and reduction in memory usage, while the segmentation performance of the initial and the optimized models remains stable, i.e., as quantified by both the Dice Similarity Coefficient and the Hausdorff Distance. These findings support post-training optimizations as a promising approach for enabling the execution of advanced DL methodologies on plain commercial-grade CPUs, and hence contributing to their translation in limited- and low- resource clinical environments.",
isbn="978-3-031-08999-2"
}

@inproceedings{karkada-etal-2022-strategy,
    title = "Strategy-level Entrainment of Dialogue System Users in a Creative Visual Reference Resolution Task",
    author = {Karkada, Deepthi  and
      Manuvinakurike, Ramesh  and
      Paetzel-Pr{\"u}smann, Maike  and
      Georgila, Kallirroi},
    booktitle = "Proceedings of the Thirteenth Language Resources and Evaluation Conference",
    month = jun,
    year = "2022",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://aclanthology.org/2022.lrec-1.620",
    pages = "5768--5777",
    abstract = "In this work, we study entrainment of users playing a creative reference resolution game with an autonomous dialogue system. The language understanding module in our dialogue system leverages annotated human-wizard conversational data, openly available knowledge graphs, and crowd-augmented data. Unlike previous entrainment work, our dialogue system does not attempt to make the human conversation partner adopt lexical items in their dialogue, but rather to adapt their descriptive strategy to one that is simpler to parse for our natural language understanding unit. By deploying this dialogue system through a crowd-sourced study, we show that users indeed entrain on a {``}strategy-level{''} without the change of strategy impinging on their creativity. Our work thus presents a promising future research direction for developing dialogue management systems that can strategically influence people{'}s descriptive strategy to ease the system{'}s language understanding in creative tasks.",
}

@INPROCEEDINGS{2021AGUFMIN31A..06T,
       author = {{Tassopoulou}, Vasiliki and {Kasmanoff}, Noah and {Soni}, Vishvesh and {Khoo}, Fech Scen and {Ward}, Kevin and {Karkada}, Deepthi and {Ramasubramanian}, Muthukumaran and {Ramachandran}, Rahul and {Soboczenski}, Frank and {Bilinski}, Piotr},
        title = "{Generating informative and accurate descriptions of natural hazards and phenomena using large transformer-based models}",
    booktitle = {AGU Fall Meeting Abstracts},
         year = 2021,
       volume = {2021},
        month = dec,
          eid = {IN31A-06},
        pages = {IN31A-06},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2021AGUFMIN31A..06T},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}
